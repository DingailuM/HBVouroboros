import os
import pandas as pd
import infref 

configfile: "/mnt/projects/HBVouroboros/align_reads/config/config.yaml"

bowtie2_index = config["bowtie2_index"]
project_name = config["project_name"]
sample_annotation = config['sample_annotation']
blast_db = config['blast_db']

# parse sample annotation
annotation = pd.read_table(sample_annotation)
samples = annotation.iloc[:, 0]
fq1s = annotation.iloc[:, 2]
fq2s = annotation.iloc[:, 3]

fq1dict = dict(zip(samples, fq1s))
fq2dict = dict(zip(samples, fq2s))

rawbam_dir = "raw_bam"
bam_dir = "bam"
log_dir = "logs"
stats_dir = "stats"
fq_dir = "fastq"
blast_dir="blast"

trinity_outdir="trinity_out_dir"
trinity_fasta=os.path.join(trinity_outdir, "Trinity.fasta")
trinity_sorted_fasta=os.path.join(trinity_outdir, "Trinity.sorted.fasta")
blast_out = os.path.join(blast_dir, "blast.out")
inferred_strain_FASTA="genotype/inferred_strain.fasta"
inferred_strain_gb="genotype/inferred_strain.gb"
inferred_strain_gff="genotype/inferred_strain.gff"

rule all:
    input:
        os.path.join(bam_dir, "aggregated_mapped_reads.bam"),  
        inferred_strain_FASTA,
        inferred_strain_gff

rule bowtie2_map:
    input:
        f1 = lambda wildcards: fq1dict[wildcards.sample],
        f2 = lambda wildcards: fq2dict[wildcards.sample]
    output:
        os.path.join(rawbam_dir, "{sample}.bam")
    log:
        "logs/{sample}_bowtie2.log"
    threads:
        2 
    shell:
        "bowtie2 -p {threads} --no-mixed --no-discordant --sensitive \
            -x {bowtie2_index} \
            -1 {input.f1} -2 {input.f2} 2>{log} | \
            samtools view -Sb - > {output}"
    
rule filter_and_sort_bam:
    input:
        os.path.join(rawbam_dir, "{sample}.bam")
    output:
        os.path.join(bam_dir, "{sample}.sorted.bam")
    log:
        os.path.join(log_dir, "{sample}_filter_and_sort_bam.log")
    threads:
        2
    shell:
        "samtools view -F4 -h {input} | samtools sort -O bam -@ {threads} - > {output}"

rule index_bam:
    input:
        os.path.join(bam_dir, "{sample}.sorted.bam")
    output:
        os.path.join(bam_dir, "{sample}.sorted.bam.bai")
    threads: 2
    shell:
        "samtools index {input}"

rule flagstat:
    input:
        bam=os.path.join(bam_dir, "{sample}.sorted.bam"),
        bai=os.path.join(bam_dir, "{sample}.sorted.bam.bai"),
    output:
        os.path.join(stats_dir, "{sample}.sorted.bam.flagstat")
    threads:
        2
    shell:
        "samtools flagstat -@ {threads} {input.bam} > {output}"

rule aggregate_bam:
    input:
        expand(os.path.join(
                bam_dir,
                "{sample}.sorted.bam"), 
            sample=samples)
    output:
        os.path.join(bam_dir, "aggregated_mapped_reads.bam")
    threads:
        2
    shell:
        "samtools cat --threads {threads} {input} | \
            samtools sort -n > {output}"
        
rule aggregate_fq:
    input:
        os.path.join(bam_dir, "aggregated_mapped_reads.bam")
    output:
        f1 = os.path.join(
             fq_dir, 
             "aggregated_mapped_reads_1.fq.gz"),
        f2 = os.path.join(
             fq_dir,
             "aggregated_mapped_reads_2.fq.gz")
    threads: 2
    shell:
        "samtools fastq --threads {threads} -N \
             -1 {output.f1} -2 {output.f2} {input}"
    
rule run_trinity:
    input:
        f1 = os.path.join(
             fq_dir, 
             "aggregated_mapped_reads_1.fq.gz"),
        f2 = os.path.join(
             fq_dir,
             "aggregated_mapped_reads_2.fq.gz")
    output:
        trinity_fasta
    threads: 2
    shell:
        "Trinity --seqType fq \
            --left {input.f1} --right {input.f2} \
            --CPU {threads} --max_memory 10G"

rule sort_trinity_fasta:
    input: trinity_fasta
    output: trinity_sorted_fasta
    run: 
        infref.sort_FASTA_by_length(input[0], output[0])

rule run_blast:
    input: trinity_sorted_fasta
    output: blast_out
    shell:
        "blastn -db {blast_db} -query {input} -outfmt 6 > {output}"

rule get_ref_strain_seq:
    input: blast_out
    output: inferred_strain_FASTA
    run:
        acc=infref.get_infref_acc(blast_out)
        infref.write_seq_by_acc(blast_db, acc, inferred_strain_FASTA)

rule get_ref_strain_gb:
    input: blast_out
    output: inferred_strain_gb
    run:
        gb_acc = infref.get_infref_gb_acc(blast_out)
        infref.download_gb(gb_acc, output[0])

rule ref_strain_gb2gff:
    input: inferred_strain_gb
    output: inferred_strain_gff
    run:
        infref.gb2gff(input[0], output[0])
"""
rule coverage:
    input:
        bam="bam/{sample}.sorted.bam",
        bai="bam/{sample}.sorted.bam.bai"
    output:
        "bedcov/{sample}.coverage"
    log:
        os.path.join(log_dir, "{sample}.coverageBed.out")
    shell:
        "coverageBed -a {BEDFILE} -b {input} -counts -F 0.5 2>{log} >{output}"
"""
